syntax = "proto3";
package influxdata.iox.ingester.v1;
option go_package = "github.com/influxdata/iox/ingester/v1";

// Request to the ingester service for data that is not yet
// persisted. This is how the querier and ingester interact.
//
// This type of message is Serialized as the Ticket value for the
// Arrow Flight doGet request.
message IngesterQueryRequest {
  // Table to search
  string table = 1;

  // Columns the query service is interested in
  repeated string columns = 2;

  // Was start time of the query; now use the one in predicate
  reserved "min_time";
  reserved 3;

  // Was end time of the query; now use the one in predicate
  reserved "max_time";
  reserved 4;

  // Predicate for filtering
  optional Predicate predicate = 5;

  // Was for only returning rows with a sequence number greater than this
  reserved "greater_than_sequence_number";
  reserved 6;

  // Namespace to search
  string namespace = 7;

  // was used to only request data from a single sequencer ID
  reserved "sequencer_id";
  reserved 8;
}

// Metadata that the ingester provides to the query service along with the results. Serialized
// in the FlightData's app_metadata for the schema that is returned as the first item from the
// Arrow Flight doGet request.
message IngesterQueryResponseMetadata {
  // There was no field 1, oops.
  reserved 1;

  // Was max persisted sequence number of the table
  reserved "max_sequencer_number";
  reserved 2;

  // Was max sequence number persisted for this table
  reserved "parquet_max_sequence_number";
  reserved 3;

  // Was max sequence number for a tombstone associated with this table
  reserved "tombstone_max_sequence_number";
  reserved 4;

  // Map partition_id to status for every partition that has unpersisted data.
  //
  // If a partition does NOT appear within this map, then either all data was persisted or the ingester has never seen
  // data for this partition. In either case the querier may just read all parquet files for the missing partition
  // and ensure it has a complete dataset
  map<int64, PartitionStatus> unpersisted_partitions = 5;

  // Map each record batch to a partition ID.
  repeated int64 batch_partition_ids = 6;
}

// Status of a partition that has unpersisted data.
//
// Note that this structure is specific to a partition (which itself is bound to a table and sequencer)!
message PartitionStatus {
  // Max sequence number persisted
  optional int64 parquet_max_sequence_number = 1;

  // Max sequence number for a tombstone associated
  optional int64 tombstone_max_sequence_number = 2;
}

// Serialization of `predicate::predicate::Predicate` that contains DataFusion `Expr`s
message Predicate {
  // Optional field restriction. If any are present, restricts the results to only tables which
  // have *at least one* of the fields in field_columns.
  repeated string field_columns = 1;

  // Optional partition key filter
  optional string partition_key = 2;

  // Optional timestamp range: only rows within this range are included in results. Other rows are
  // excluded.
  optional TimestampRange range = 3;

  // Optional arbitrary predicates, represented as list of DataFusion expressions applied a logical
  // conjunction (aka they are 'AND'ed together). Only rows that evaluate to TRUE for all these
  // expressions should be returned. Other rows are excluded from the results.
  //
  // Encoded using DataFusion's Expr serialization code
  repeated bytes exprs = 4;

  // Optional arbitrary predicates on the special `_value` column. These expressions are applied to
  // `field_columns` projections in the form of `CASE` statement conditions.
  repeated ValueExpr value_expr = 5;
}

// Specifies a continuous range of nanosecond timestamps.
message TimestampRange {
  // Start defines the inclusive lower bound.
  int64 start = 1;

  // End defines the exclusive upper bound.
  int64 end = 2;
}


// A wrapper around a DataFusion expression against `_value` columns
message ValueExpr {
  // Encoded using DataFusion's Expr serialization code
  bytes expr = 1;
}
